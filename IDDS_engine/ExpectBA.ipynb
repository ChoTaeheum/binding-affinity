{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% library import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch as tc\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import xlsxwriter\n",
    "\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import _mysql\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from ba_const import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class CallDB:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine(\"mysql+mysqldb://{}:{}@{}/{}\".format(USER_NAME, USER_PSWD, DB_HOST, DB_NAME), encoding='utf-8')\n",
    "    \n",
    "    def query_db(self, query):\n",
    "        dbconn = _mysql.connect(host=DB_HOST, user=USER_NAME, passwd=USER_PSWD, port=PORT, db=DB_NAME)\n",
    "        self.cursor = dbconn.cursor()\n",
    "        self.cursor.execute(query)\n",
    "        dbconn.commit()\n",
    "        dbconn.close()\n",
    "    \n",
    "    def to_db(self, data, table_nm):\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_sql(name=table_nm, con=self.engine, if_exists='append', index=False)\n",
    "        \n",
    "    def from_db(self, query):\n",
    "        dbconn = _mysql.connect(host=DB_HOST, user=USER_NAME, passwd=USER_PSWD, port=PORT, db=DB_NAME)\n",
    "        self.cursor = dbconn.cursor()\n",
    "        self.cursor.execute(query)\n",
    "        table = self.cursor.fetchall()\n",
    "        dbconn.commit()\n",
    "        dbconn.close()\n",
    "        return pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class PreprocessData:\n",
    "    def __init__(self):\n",
    "        call_db = CallDB()\n",
    "        pr_query = \"SELECT req_id, uniprot_id, protein_seq FROM bd_uniprot_info where req_id = (SELECT req_id FROM req_info order by req_id desc limit 1)\"\n",
    "        li_query = \"SELECT req_id, chembl_id, smiles FROM bd_ligand_info where req_id = (SELECT req_id FROM req_info order by req_id desc limit 1)\"\n",
    "        kiba_query = \"select * from kiba_score\"\n",
    "        \n",
    "        self.req_id = call_db.from_db(pr_query).iloc[0, 0]\n",
    "        self.prt_df = call_db.from_db(pr_query).iloc[:, 1:]\n",
    "        self.lgn_df = call_db.from_db(li_query).iloc[:, 1:]\n",
    "\n",
    "    def encoder(self):\n",
    "        prtlen = len(self.prt_df)\n",
    "        lgnlen = len(self.lgn_df)\n",
    "        \n",
    "        prt_seqs = np.zeros((prtlen, 1400), dtype=int)\n",
    "        lgn_seqs = np.zeros((lgnlen, 100), dtype=int)\n",
    "        \n",
    "        for i, row in enumerate(self.prt_df.iterrows()):\n",
    "            prt_seq = row[1][2][:1400]\n",
    "            for j, t in enumerate(prt_seq):\n",
    "                prt_seqs[i, j] = AMINO_SIGN[t]\n",
    "        del i, j, t, prt_seq\n",
    "        \n",
    "        for i, row in enumerate(self.lgn_df.iterrows()):\n",
    "            lgn_seq = row[1][2][:100]\n",
    "            for j, t in enumerate(lgn_seq):\n",
    "                lgn_seqs[i, j] = SMILES_SIGN[t]\n",
    "        del i, j, t, lgn_seq\n",
    "\n",
    "        prt_ids = np.array(self.prt_df.iloc[:, 0])\n",
    "        lgn_ids = np.array(self.lgn_df.iloc[:, 0])\n",
    "        \n",
    "        prt_data = np.reshape(np.array([], dtype=int), (0, 1400))\n",
    "        lgn_data = np.reshape(np.array([], dtype=int), (0, 100))\n",
    "        for prt_seq in prt_seqs:\n",
    "            for lgn_seq in lgn_seqs:\n",
    "                prt_data = np.vstack((prt_data, prt_seq))\n",
    "                lgn_data = np.vstack((lgn_data, lgn_seq))\n",
    "                \n",
    "        prt_label = []\n",
    "        lgn_label = []\n",
    "        for prt_id in prt_ids:\n",
    "            for lgn_id in lgn_ids:\n",
    "                prt_label.append(prt_id)\n",
    "                lgn_label.append(lgn_id)\n",
    "        id_index = pd.DataFrame([prt_label, lgn_label]).T\n",
    "                \n",
    "        return self.req_id, prt_data, lgn_data, id_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()    # method 상속받고 __init__()은 여기서 하겠다.\n",
    "        \n",
    "        self.prt_emlayer = nn.Embedding(21, 10)\n",
    "        \n",
    "        self.prt_cv1dlayers = nn.Sequential(\n",
    "                        nn.Conv1d(10, 32, kernel_size = 4),\n",
    "                        nn.BatchNorm1d(num_features = 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(32, 64, kernel_size = 8),\n",
    "                        nn.BatchNorm1d(num_features = 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(64, 96, kernel_size = 12),\n",
    "                        nn.BatchNorm1d(num_features = 96),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool1d(kernel_size=1379)\n",
    "                        )\n",
    "        \n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        \n",
    "        self.lgn_emlayer = nn.Embedding(64, 10)\n",
    "        \n",
    "        self.lgn_cv1dlayers = nn.Sequential(\n",
    "                        nn.Conv1d(10, 32, kernel_size = 4),\n",
    "                        nn.BatchNorm1d(num_features = 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(32, 64, kernel_size = 6),\n",
    "                        nn.BatchNorm1d(num_features = 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv1d(64, 96, kernel_size = 8),\n",
    "                        nn.BatchNorm1d(num_features = 96),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool1d(kernel_size = 85)\n",
    "                        )\n",
    "\n",
    "        self.mlplayers = nn.Sequential(\n",
    "                        nn.Linear(192, 1024),\n",
    "                        nn.BatchNorm1d(1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.1),\n",
    "                        nn.Linear(1024, 1024),\n",
    "                        nn.BatchNorm1d(1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.1),\n",
    "                        nn.Linear(1024, 1024),\n",
    "                        nn.BatchNorm1d(1024),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.1),\n",
    "                        nn.Linear(1024, 512),\n",
    "                        nn.BatchNorm1d(512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.1),\n",
    "                        nn.Linear(512, 512),\n",
    "                        nn.BatchNorm1d(512),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "\n",
    "        self.regress = nn.Linear(512, 1)    # regression\n",
    "\n",
    "    def forward(self, prt_seq, lgn_seq):   \n",
    "        p = self.prt_emlayer(prt_seq)\n",
    "        p = p.permute(0, 2, 1)\n",
    "        p = self.prt_cv1dlayers(p)\n",
    "        p = p.squeeze()\n",
    "        \n",
    "        l = self.lgn_emlayer(lgn_seq)\n",
    "        l = l.permute(0, 2, 1)\n",
    "        l = self.lgn_cv1dlayers(l)\n",
    "        l = l.squeeze()\n",
    "        \n",
    "        cat = tc.cat((p, l), axis=1).cuda()\n",
    "        out = self.mlplayers(cat)\n",
    "        \n",
    "        return self.regress(out).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "class ExpectBA:\n",
    "    def __init__(self):\n",
    "        preprocess = PreprocessData()\n",
    "        self.req_id, prt_data, lgn_data, self.id_index = preprocess.encoder()\n",
    "        smplen = len(self.id_index)\n",
    "                \n",
    "        model = Regressor().to(tc.device('cuda:0'))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=(10**-3.563), weight_decay=(10**-5), eps=(10**-8))\n",
    "        \n",
    "        checkpoint = tc.load(CHECKPOINT)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        loss = checkpoint['loss']\n",
    "        model.eval()\n",
    "        \n",
    "        prt_data = tc.tensor(prt_data, dtype=tc.int64).cuda()\n",
    "        lgn_data = tc.tensor(lgn_data, dtype=tc.int64).cuda()\n",
    "        \n",
    "        prediction = np.array(model(prt_data, lgn_data).detach().cpu())\n",
    "        self.prediction = pd.DataFrame((prediction-MEAN) / STD)\n",
    "        \n",
    "        self.table = pd.DataFrame({'req_id': self.req_id,\n",
    "                                   'index_id': np.arange(1, smplen+1),\n",
    "                                   'uniprot_id': self.id_index.iloc[:, 0],\n",
    "                                   'chembl_id': self.id_index.iloc[:, 1],\n",
    "                                   'ba_score': self.prediction.iloc[:, 0]\n",
    "                                   })\n",
    "        \n",
    "        self.to_db()\n",
    "    \n",
    "    def to_db(self):\n",
    "        db = CallDB()\n",
    "        db.to_db(self.table, 'bd_result')\n",
    "        \n",
    "    def get_result(self):\n",
    "        return self.req_id, self.table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
